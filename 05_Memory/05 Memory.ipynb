{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3388f2cc-89f6-40e9-a7e8-4e9c6c532a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487809e-cdea-4aaf-9500-2bd879922044",
   "metadata": {},
   "source": [
    "# 기본 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb98baf-a742-4305-afbb-75820ca55fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9163e80-6462-487a-917b-a8d0200dd742",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "https://python.langchain.com/api_reference/langchain/memory.html\n",
    "\n",
    "챗봇으로 하여금 대화(상태)를 '기억'하게끔 한다\n",
    "\n",
    "Memory maintains Chain state, incorporating context from past runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453fcf0c-4e78-4cbb-aa1a-762023f99184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain 의 memory 계층\n",
    "#  BaseMemory --> BaseChatMemory --> <name>Memory  # Examples: ZepMemory, MotorheadMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07fbf1-e713-4016-b765-9294ee49c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 사에서 제공하는 '기본 API' 도 랭체인 없이 사용 가능.\n",
    "# 메모리 지원하지 않는다.  이전 대화 기억 못함.  stateless 하다!\n",
    "\n",
    "# ChatGPT 서비스 는 '메모리' 기능이 탑재되어 있다.\n",
    "# 챗봇이 이전의 대화 내용과 질문을 기억하고 답할수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7471eca7-4e9b-4312-90a0-137fca5d12a1",
   "metadata": {},
   "source": [
    "# 1.ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b195567f-4256-434e-af4b-098a0a9c30db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationBufferMemory\n",
    "# 대화 내용 '전체'를 저장하는 메모리\n",
    "\n",
    "# 장점: 단순하다\n",
    "\n",
    "# 단점:\n",
    "# => 매번 요청할때마다 '이전 대화 기록 전체' 를 같이 보내야 함.\n",
    "#  그래야 모델이 전에 일어났던 대화를 보고 이해 할수 있다.\n",
    "#  대화내용이 길어질수록 메모리도 계속 커지니까 성능적으로도 & 비용적으로도 비효율적이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53c506b-d6fd-454f-8fed-22e660116e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.buffer import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e7c0cd-7d3c-4bb9-a5b1-47c0963cb0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi!\\nAI: How are you?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# 직접 save\n",
    "memory.save_context(\n",
    "    {'input': 'Hi!'},   # 유저 입력값\n",
    "    {'output': 'How are you?'}, # AI 가 유저에게 답한 내용 기록\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({})   # inputs= 매개변수가 빈dict\n",
    "\n",
    "\n",
    "# {'history': 'Human: Hi!\\nAI: How are you?'}\n",
    "#  history 가 텍스트다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d664eb9-e170-433c-b0ac-009c74af1272",
   "metadata": {},
   "source": [
    "## return_messages=True\n",
    "history 에  AIMessage 와 HumanMessage 로 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b2a4c92-4ec2-43f5-ad35-2f7865ce017d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1466910a-fafd-41d0-908b-10446f4b4fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {'input': 'Hi!'},   # 유저 입력값\n",
    "    {'output': 'How are you?'}, # AI 가 유저에게 답한 내용 기록\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "# {'history': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
    "#   AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}\n",
    "\n",
    "#  history 가 Message 의 list 다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0a595b-dfad-4c09-b81d-b03733136acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {'input': 'Hi!'},   # 유저 입력값\n",
    "    {'output': 'How are you?'}, # AI 가 유저에게 답한 내용 기록\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e97ca-333b-409d-a95c-4e9d212bbcfa",
   "metadata": {},
   "source": [
    "# 2.ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf12f00-2e36-41af-b2a7-29449b7fc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.buffer_window import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbe919-9fcb-49a1-adbb-a5bb4f10db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationBufferWindowMemory 는 대화의 '특정 부분만' 을 저장하는 메모리.\n",
    "\n",
    "# 장점:\n",
    "#   메모리를 특정 크기로 유지할 수 있다!\n",
    "#   따라서 모든 대화 내용을 저장하지 않아도 된다!\n",
    "\n",
    "# 단점:\n",
    "#   챗봇이 전체 대화가 아닌 '최근 대화' 에만 집중하게 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02016dc-c558-41af-bc55-280f1f5ab98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_14796\\823005658.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4,   # 버퍼 윈도우 사이즈.  몇개의 context(메세지)를 저장할지 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b7d4de0-4cdf-403d-8cf5-ad5eb91d9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도우미 함수 준비.\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c0ecfb2-aa89-48b8-bd37-28bfcf27cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동작 확인\n",
    "add_message(\"1\", \"1\")\n",
    "add_message(\"2\", \"2\")\n",
    "add_message(\"3\", \"3\")\n",
    "add_message(\"4\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f374830b-71ac-400a-9c71-e9795b54c1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='1', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='4', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23e4fbca-47d9-4a1d-a0d0-4e121493bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='5', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='5', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"5\", \"5\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365dbdc8-00e4-4dc8-bc78-3afc40905ef5",
   "metadata": {},
   "source": [
    "# 3.ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c2e94-d186-479d-aad6-2c3fcc77eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationSummaryMemory 는 LLM 을 사용하여 대화의 요약본 (summary) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "637a5f93-86ac-421f-91aa-640de47f5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb0e166c-3870-437e-9c3d-893a79807edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.summary import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08b4b32-4ed0-4488-b6e6-40678abc096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_14796\\2664529100.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)  # llm 을 사용하여 요약한다!\n"
     ]
    }
   ],
   "source": [
    "# ConversationSummaryMemory\n",
    "# 메세지를 그대로 저장하는 것이 아니라 Convertaion 의 '요약'을 해준다. LLM 필요\n",
    "\n",
    "# 장점: 대화의 메세지가 많아질수록 요약을 해주어 토큰의 양도 줄어들어 훨씬 경제적인 방법\n",
    "# 단점: LLM 호출 발생\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)  # llm 을 사용하여 요약한다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f9276b5-0b31-4893-b060-51585f6b3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history():\n",
    "    return memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39fa6873-c7ab-4ec7-ae85-e49d2fe1fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message 추가\n",
    "add_message(\n",
    "    \"Hi I'm John, I live in South Korea\",    # input\n",
    "    \"Wow that is so cool!\"  # output : AI 답변\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b118210-f1df-4a1d-88a7-d0c8ea7361a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또 message 추가\n",
    "add_message(\n",
    "    \"South Korea is so pretty\",\n",
    "    \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "742bba6a-d9bd-4dc5-94bb-648860cd8a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'John introduces himself as living in South Korea. The AI responds by expressing admiration for his location, wishing it could go there.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c00d5a-8ffe-43d9-9f98-dc4a11e433ca",
   "metadata": {},
   "source": [
    "# 4.ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f867090e-2efe-4074-ba7e-0ddf5a1c87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.summary_buffer import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c6c4df0-2d46-458f-a5cc-18a733abe0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_14796\\2068819690.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,   # 최대 가용한 메세지 토큰수 (메세지들이 요약되지 전)\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c528222d-b387-43ba-930e-607d5de7c716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm John, I live in South Korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\n",
    "    \"Hi I'm John, I live in South Korea\",    # input\n",
    "    \"Wow that is so cool!\"  # output : AI 답변\n",
    "    )\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14aacab8-3b46-4e59-8057-b87c23c57823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm John, I live in South Korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South Korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다시 메세지 추가하고 history 확인\n",
    "add_message(\n",
    "    \"South Korea is so pretty\",\n",
    "    \"I wish I could go!!!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "212157c3-129d-4437-accb-1a93ad32177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm John, I live in South Korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South Korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Korea from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\n",
    "    \"How far is Korea from Argentina?\",\n",
    "    \"I don't know! Super far!\"\n",
    ")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f780be-4503-4eb1-8a25-10e746ec529f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human introduces himself as John and mentions that he lives in South Korea.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South Korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Korea from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래 셀을 여러차레 해보자  약 (3,4번?)\n",
    "# =>실제 '요약'이 발생할때면 Model IO 가 발생하기 때문에 시간이 좀 걸리는게 느껴질거다!\n",
    "add_message(\n",
    "    \"How far is Brazil from Argentina?\",\n",
    "    \"I don't know! Super far!\"\n",
    ")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b0e71d-be03-4e15-8e48-346f09416de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_token_limit 에 도달하면, 오래된 메세지들이 요약되고 있을 것을 확인할수 있다. (SystemMessage 확인)\n",
    "\n",
    "# ★그러나 '요약' 이라는 과정은 API 를 사용한다는 사실을 명심하세요.\n",
    "# ★'요약' 동작은 비용 지출이 발생되는 부분입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d01da10-d82f-437b-8c86-0e1182ad24d3",
   "metadata": {},
   "source": [
    "# 5.ConversationKGMemory\n",
    "KG : Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f4d6394-9cbe-4f60-a946-6b3caa366ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화중에 '엔티티'의 knowledge graph 를 형성한다 => 가장 중요한 것들만 추출한 요약본.\n",
    "# knowledge graph 는 history 를 가지고 오지 않는다.  대신 '엔티티' 를 가지고 옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b6a73d-b89c-4ee6-ab10-dc34f7600e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.memory.kg import ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf882e89-2de6-4f00-acab-10b48282a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationKGMemory(\n",
    "    llm=llm,  # 이 또한 LLM 을 사용하는 Memory 다  -> Knowledge Graph 를 만든다. (가장 중요한것만 뽑아낸 요약본)\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "745358e3-8584-4a1c-8145-a2a50fdb8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\n",
    "    \"Hi I'm John, I live in South Korea\",    # input\n",
    "    \"Wow that is so cool!\"  # output : AI 답변\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddf3d29b-f2aa-4e4e-9af7-da1a9757e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On John: John lives in South Korea.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대화의 특정 entity 에 대해 질무ㄴ해보자\n",
    "#  Model IO 발생\n",
    "memory.load_memory_variables({\"input\": \"Who is John\"})   # 빈dict 가 아니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c46e586d-54be-474c-b777-98dbd2484c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"John likes kimchi\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3b2166b-37ae-430f-b0a5-9c42aedc0515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On John: John lives in South Korea. John likes kimchi.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"Who is John\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56f980-94fe-4090-a440-ecedfbbf135a",
   "metadata": {},
   "source": [
    "# 6. 참고: Database 와 integration 된 메모리들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034f6f9-dc16-4aab-98ea-8875327f5f28",
   "metadata": {},
   "source": [
    "- **참고: Database 와 integration 된 메모리들**\n",
    "\n",
    "| Memory Class                  | 통합 대상 (Integration)             | 설명                                                           |\n",
    "| ----------------------------- | ------------------------------- | ------------------------------------------------------------ |\n",
    "| `RedisChatMessageHistory`     | **Redis**                       | Redis에 메시지 저장. 빠르고 확장 가능한 저장소.                               |\n",
    "| `SQLChatMessageHistory`       | **SQLite, PostgreSQL 등 SQL DB** | SQL 데이터베이스에 메시지 저장. SQLAlchemy 기반.                           |\n",
    "| `DynamoDBChatMessageHistory`  | **AWS DynamoDB**                | AWS의 NoSQL DB인 DynamoDB에 대화 저장. 서버리스 환경에서 유용.                |\n",
    "| `MongoDBChatMessageHistory`   | **MongoDB**                     | 문서 기반 DB인 MongoDB와 통합하여 대화 저장.                               |\n",
    "| `PostgresChatMessageHistory`  | **PostgreSQL**                  | PostgreSQL 전용 구현 (SQLAlchemy 없이).                            |\n",
    "| `FileChatMessageHistory`      | **Local 파일**                    | JSON 파일로 로컬에 저장. 간단한 로깅에 적합.                                 |\n",
    "| `FirestoreChatMessageHistory` | **Google Firestore**            | Firebase 기반 클라우드 NoSQL DB와 통합.                               |\n",
    "| `ChromaMemory`                | **Chroma (벡터 DB)**              | 벡터 DB에 embedding 형태로 memory 저장. RAG나 유사 검색 기반 memory에 활용 가능. |\n",
    "| `WeaviateMemory`              | **Weaviate**                    | Weaviate 벡터 DB와 통합된 memory 저장.                               |\n",
    "| `QdrantMemory`                | **Qdrant**                      | 벡터 기반 memory 저장소로 Qdrant 사용.                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e62037-e441-477f-8755-8e50cabbdbeb",
   "metadata": {},
   "source": [
    "# 7.Memory on LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7174b24-5ac6-47af-84d3-1f12c2d1189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리를 'chain' 에 꽂는 방법.\n",
    "# 두가지 형태의 'chain' 에 각각 꽂는 방법.\n",
    "#    1. off-the-shelf chain  : LangChain 에서 '일반적인 목적'을 수행하는 기본 제공되는 chain\n",
    "#    2. LCEL 사용한 chain : 커스텀 chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "954a1f39-0b31-4930-9fad-41323cb25f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48be0f66-442c-4159-8723-cb448a9cc920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_14796\\2707029833.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(   # prompt | llm\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm, \n",
    "    max_token_limit=80,\n",
    ")\n",
    "\n",
    "chain = LLMChain(   # prompt | llm\n",
    "    llm=llm,\n",
    "    memory=memory,  # 메모리 제공\n",
    "    prompt=PromptTemplate.from_template(\"{question}\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cba54564-413f-4514-b2be-d4acb1009d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is John',\n",
       " 'history': '',\n",
       " 'text': 'Nice to meet you, John! How can I assist you today?'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"question\": \"My name is John\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01347696-7bd3-4836-88a4-b98f213d83d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'I live in Seoul',\n",
       " 'history': 'Human: My name is John\\nAI: Nice to meet you, John! How can I assist you today?',\n",
       " 'text': ', the capital city of South Korea. It is a vibrant and bustling metropolis with a rich history and culture. There are so many things to see and do in Seoul, from visiting ancient palaces and temples to exploring modern shopping districts and enjoying delicious Korean cuisine. I love living in Seoul because of its dynamic energy and the endless opportunities for adventure and exploration.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"question\": \"I live in Seoul\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3debc5b4-54f3-4711-a90e-f3c8dcd2605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is my name?',\n",
       " 'history': 'System: The human introduces himself as John. The AI greets John and asks how it can assist him. John mentions that he lives in Seoul.\\nAI: , the capital city of South Korea. It is a vibrant and bustling metropolis with a rich history and culture. There are so many things to see and do in Seoul, from visiting ancient palaces and temples to exploring modern shopping districts and enjoying delicious Korean cuisine. I love living in Seoul because of its dynamic energy and the endless opportunities for adventure and exploration.',\n",
       " 'text': \"I'm sorry, I do not know your name as I am an AI assistant and do not have access to personal information.\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 과연 이름을 기억하고 있을까?\n",
    "chain.invoke(input={'question':'What is my name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f782e2c-30ab-4553-8982-35fac43c9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이름을 모른다고???\n",
    "\n",
    "# chain 을 디버깅해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaced07-d656-4d96-b5bf-ec3e620bca9e",
   "metadata": {},
   "source": [
    "## verbose=\n",
    "chain 을 실행했을때 chain 의 프롬프트와 로그들을 확인할수 있다. (디버깅용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0e493d5-92e0-4678-bb70-1446ebde3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mMy name is John\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI live in Seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is my name?',\n",
       " 'history': \"System: The human, named John, mentions that he lives in Seoul. The AI responds by acknowledging John's name and location, expressing pleasure in meeting him and offering assistance.\\nAI: , the capital city of South Korea. It is a bustling metropolis with a vibrant culture, delicious food, and a mix of modern skyscrapers and historic palaces. I love exploring the city's neighborhoods, trying new restaurants, and taking in the beautiful views from Namsan Mountain. Seoul is a dynamic and exciting place to call home.\",\n",
       " 'text': \"I'm sorry, I do not have access to personal information such as your name.\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(\"{question}\"),\n",
    "    verbose=True,  # chain 을 실행했을때 chain 의 프롬프트 로그들을 확인할수 있다. (디버깅용)\n",
    ")\n",
    "\n",
    "chain.invoke(input={'question':\"My name is John\"})\n",
    "chain.invoke(input={'question':\"I live in Seoul\"})\n",
    "chain.invoke(input={'question':\"What is my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691d4a3-030a-4a6a-9567-b4c428423dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↑ chain 의 prompt 로그 들을 확인할 수 있다.\n",
    "# 보다시피 대화의 내역(history) 가 prompt에 계속 추가되진 않는다.\n",
    "\n",
    "# 우리가 원하는 어떤 방식으로 prompt에게 대화 기록(history)을 추가해줘야 한다!\n",
    "\n",
    "# ↓ 하지만! 메모리는 계속 업데이트 된다.  함 보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79552760-45f5-48a9-b74a-5b567789076b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: John mentions that he lives in Seoul, the capital city of South Korea. The AI responds by acknowledging John's name and location, expressing pleasure in meeting him and offering assistance. The AI then shares its love for Seoul, describing it as a bustling metropolis with a vibrant culture, delicious food, and a mix of modern skyscrapers and historic palaces. The AI enjoys exploring the city's neighborhoods, trying new restaurants, and taking in the beautiful views from Namsan Mountain, considering Seoul a dynamic and exciting place to call home.\\nHuman: What is my name?\\nAI: I'm sorry, I do not have access to personal information such as your name.\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0463eb60-da02-41cd-883f-3104fb270668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 메모리 내용이 prompt 에 포함되어야 한다!\n",
    "\n",
    "# memory_key= 에 \"chat_history\" 라고 말해주어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360cf80-6df3-4063-9b8c-ef67055ace89",
   "metadata": {},
   "source": [
    "## memory_key="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61864dce-749d-4dae-8508-8a7bd0a1c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\", \n",
    ")\n",
    "\n",
    "# ↓ template 안에는 memory 가 history 를 저장하도록 한 곳을 적어주기만 하면 된다\n",
    "# history 까지 담을 괜찮은 템플릿을 준비해보자\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human:{question}\n",
    "    You:\n",
    "\"\"\"\n",
    "# AI 가 우리의 대화기록을 기억하면서 여기의 question 을 완성할 수 있기를 기대해보자.\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),  # <- template 지정\n",
    "    verbose=True,  # 어떤 prompt 가 만들어질까?  두근두근\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdc3e7d8-61fa-4429-bb02-bf88cdb05ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    \n",
      "    Human:My name is John\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is John',\n",
       " 'chat_history': '',\n",
       " 'text': 'Hello John! How can I assist you today?'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question': \"My name is John\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "653166f0-903e-4277-8099-e40c4432dd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is John\n",
      "AI: Hello John! How can I assist you today?\n",
      "    Human:I live in Seoul\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'I live in Seoul',\n",
       " 'chat_history': 'Human: My name is John\\nAI: Hello John! How can I assist you today?',\n",
       " 'text': \"That's great to know! How can I assist you with information or tasks related to Seoul?\"}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question': \"I live in Seoul\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d702446-2d9c-473e-8b48-e556af6e7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is John\n",
      "AI: Hello John! How can I assist you today?\n",
      "Human: I live in Seoul\n",
      "AI: That's great to know! How can I assist you with information or tasks related to Seoul?\n",
      "    Human:What is my name?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is my name?',\n",
       " 'chat_history': \"Human: My name is John\\nAI: Hello John! How can I assist you today?\\nHuman: I live in Seoul\\nAI: That's great to know! How can I assist you with information or tasks related to Seoul?\",\n",
       " 'text': 'Your name is John.'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question':'What is my name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a135eb37-2134-4811-b133-6eaf60c6ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 프롬프트 템플릿 안에서 메모리 내용이 들어갈 공간을 준비한다.  (예: chat_history)\n",
    "# - 메모리를 활용할 템플릿은 원하는대로 작성하면 된다.\n",
    "# - Memory 클래스에선 history 를 어디에 꽂을지 지정해준다 (memory_key=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ecc3b-8eab-4ef7-8a7d-fb232b0be2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebe5ea-dc80-4103-864e-944b6abec334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778179ca-3432-4737-81f0-502b001c9a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0136ff-7a83-4a3b-b2f3-31bcf6428a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67216f7-a176-4b1f-8a32-81158ca3b83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b25826-d5b6-4714-b4b8-01c508c41003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf5689-f0a9-4869-a6c7-b600c7a44b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2b6a6-708c-434f-b810-a3b42397d5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d326bb-0073-43e1-b262-9cbd177f2547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee83d40-83f7-42be-a7a7-73c32a19164e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02e3ac-98d5-4763-98d4-445394ea521b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f4341-8aea-46e8-ab4e-998c46d6bb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350edfc4-09ac-47a2-a085-58fe1e2efe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c4262-c0d0-4aba-b337-bd88d661ca76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bece7d2-988e-490e-a4ae-34e66cbe8c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec608e2-e61a-4923-a65e-8d0df2d71184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793c23a-5158-4132-9a14-b7ecfc1d8753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
