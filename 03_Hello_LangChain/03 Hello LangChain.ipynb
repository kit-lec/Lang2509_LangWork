{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bc5494-15c5-4a75-9fed-ec94e8ca8cae",
   "metadata": {},
   "source": [
    "# Hello LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfe36a-97a9-4c12-9d08-3453b6a02488",
   "metadata": {},
   "source": [
    "# LangChain  ê´€ë ¨ ì£¼ìš” ë§í¬\n",
    "\n",
    "-  Python Langchain ê³µì‹ í™ˆ:  https://python.langchain.com/\n",
    "-  API ë ˆí¼ëŸ°ìŠ¤ í™ˆ: https://python.langchain.com/api_reference/reference.html\n",
    "\n",
    "\n",
    "## Langchain ì˜ íŒ¨í‚¤ì§€ êµ¬ì„±\n",
    "\n",
    "\n",
    "### Base Packages\n",
    "- [Core: langchain-core](https://python.langchain.com/api_reference/core)\n",
    "- [Langchain: langchain](https://python.langchain.com/api_reference/langchain)\n",
    "- [Test Splitters: langchain-text-splitters](https://python.langchain.com/api_reference/text_splitters)\n",
    "- [Community: langchain-community](https://python.langchain.com/api_reference/community)\n",
    "- [Experimental: langchain-experimental](https://python.langchain.com/api_reference/experimental)\n",
    "\n",
    "### Integrations\n",
    "- ë­ì²´ì¸ì€ ìˆ˜ë§ì€ LLM ëª¨ë¸ë“¤ê³¼ ì»¤ë®¤ë‹ˆí‹°, ë²¡í„°ìŠ¤í† ì–´, ë°ì´í„°ë² ì´ìŠ¤, íˆ´ ë“¤ê³¼ í•¨ê»˜ ì‚¬ìš©í• ìˆ˜ ìˆë„ë¡ ì œê³µë˜ëŠ” íŒ¨í‚¤ì§€ë“¤ì´ ë§ë‹¤ (ì•ìœ¼ë¡œ ë” ë§ì•„ ì§ˆê±°ë‹¤)\n",
    "- [OpanAI: langchain-openai](https://python.langchain.com/api_reference/openai)\n",
    "- [Huggingface: langchain-huggingface](https://python.langchain.com/api_reference/huggingface)\n",
    "- [MistalAI: langchain-mistralai](https://python.langchain.com/api_reference/mistralai)\n",
    "- ê·¸ë°–ì—ë„ ë§ì´ ìˆë‹¤ ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae530e4-32d8-4da3-a334-9276d765a162",
   "metadata": {},
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49112a72-90be-43aa-ae2b-617da279d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47043fc7-4e77-4fde-ae7c-ed4b316d88e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90835ee8-4857-4493-a6ce-52bae00ba99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-iKU13YeoxNgF...\n"
     ]
    }
   ],
   "source": [
    "print(f'{os.environ['OPENAI_API_KEY'][:20]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b54a00-ed86-4352-8800-3dc94bc51de8",
   "metadata": {},
   "source": [
    "# â–  LLM vs. Chat model\n",
    "\n",
    "LangChain ì€ LLM ê³¼ Chat model ë‘ê°€ì§€ë¥¼ ì§€ì›í•©ë‹ˆë‹¤\n",
    "\n",
    "`LLM`(Large Language Model)ê³¼ `Chat Model`ì€ ë¹„ìŠ·í•œ ì—­í• ì„ í•˜ì§€ë§Œ, ì•½ê°„ì˜ ì°¨ì´ì ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŠ” ì£¼ë¡œ **ëª¨ë¸ì˜ ì…ë ¥ ë° ìƒí˜¸ì‘ìš© ë°©ì‹**ì—ì„œ ë‚˜íƒ€ë‚œë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. LLM (Large Language Model)\n",
    "- **íŠ¹ì§•**:\n",
    "  - ì¼ë°˜ì ìœ¼ë¡œ **í…ìŠ¤íŠ¸ ì…ë ¥**ì„ ë°›ê³ , ì´ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "  - ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì…ë ¥/ì¶œë ¥ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "  - ì‚¬ìš©ìê°€ ì œê³µí•œ ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³ , ê·¸ì— ëŒ€í•œ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "- **ì…ë ¥ í˜•ì‹**:\n",
    "  ```plaintext\n",
    "  \"Tell me a summary of the benefits of LangChain.\"\n",
    "  ```\n",
    "- **ì¶œë ¥ í˜•ì‹**:\n",
    "  ```plaintext\n",
    "  \"LangChain is a framework designed to simplify the development of applications powered by large language models, making it easier to manage prompts, chains, and integrations.\"\n",
    "  ```\n",
    "- **ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€**:\n",
    "  - ë‹¨ì¼ ì§ˆë¬¸-ë‹µë³€\n",
    "  - í…ìŠ¤íŠ¸ ìƒì„±\n",
    "  - ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‘ì—…\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Chat Model\n",
    "- **íŠ¹ì§•**:\n",
    "  - **ëŒ€í™” í˜•ì‹**ìœ¼ë¡œ ì„¤ê³„ëœ ëª¨ë¸ë¡œ, ë‹¤ì¤‘ í„´ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.\n",
    "  - ì…ë ¥ í˜•ì‹ì´ **ë©”ì‹œì§€ Message**ë¡œ êµ¬ì„±ë˜ë©°, ê° ë©”ì‹œì§€ëŠ” ì‚¬ìš©ìì˜ ë©”ì‹œì§€ (User Message)ì™€ ì‹œìŠ¤í…œì˜ ë©”ì‹œì§€(System Message)ë¡œ ë‚˜ë‰œë‹¤.\n",
    "  - 'ë¬¸ë§¥'ì„ ì´í•´í•˜ê³  'ëŒ€í™”ì˜ íë¦„'ì„ ìœ ì§€í•˜ëŠ” ë° ìµœì í™”ë˜ì–´ ìˆë‹¤.\n",
    "- **ì…ë ¥ í˜•ì‹**:\n",
    "  ë©”ì‹œì§€ ê°ì²´ë¥¼ ì „ë‹¬í•´ì•¼ í•˜ë©°, ë³´í†µ ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
    "  ```python\n",
    "  [\n",
    "      {\"role\": \"system\", \"content\": \"You are an assistant who helps with Python programming.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Can you explain the difference between LLM and chat models in LangChain?\"}\n",
    "  ]\n",
    "  ```\n",
    "- **ì¶œë ¥ í˜•ì‹**:\n",
    "  ```python\n",
    "  {\"role\": \"assistant\", \"content\": \"Sure! LLM and Chat Models differ in their input and interaction styles...\"}\n",
    "  ```\n",
    "- **ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€**:\n",
    "  - ë‹¤ì¤‘ í„´ ëŒ€í™”\n",
    "  - ë¬¸ë§¥ ì¶”ì  ë° ìœ ì§€ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜ì˜)\n",
    "  - ëŒ€í™” ê¸°ë°˜ ì±—ë´‡, FAQ ì‹œìŠ¤í…œ ë“±\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ì£¼ìš” ì°¨ì´ì  ìš”ì•½\n",
    "| **íŠ¹ì§•**        | **LLM**                                                | **Chat Model**                                        |\n",
    "|-----------------|------------------------------------------------------|----------------------------------------------------|\n",
    "| **ì…ë ¥ í˜•ì‹**   | ë‹¨ì¼ í…ìŠ¤íŠ¸ ì…ë ¥                                         | ì—­í•  ê¸°ë°˜ì˜ ëŒ€í™” ë©”ì‹œì§€ ê°ì²´ (role: system, user, assistant) |\n",
    "| **ëŒ€í™” íˆìŠ¤í† ë¦¬**| ë¬¸ë§¥ ì¶”ì  ë¶ˆê°€ëŠ¥ (ë‹¨ì¼ ìš”ì²­ ì²˜ë¦¬)                          | ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í†µí•´ ë¬¸ë§¥ì„ ìœ ì§€í•˜ê³  ë°˜ì˜                 |\n",
    "| **ì‚¬ìš© ëª©ì **   | í…ìŠ¤íŠ¸ ìƒì„±, ìš”ì•½, ë‹¨ìˆœ ì§ˆì˜ì‘ë‹µ                             | ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤, ì±—ë´‡, ë‹¤ì¤‘ í„´ ì§ˆì˜ì‘ë‹µ               |\n",
    "| **ì‘ìš© ì‚¬ë¡€**   | ë‹¨ì¼ ì§ˆë¬¸-ë‹µë³€, í…ìŠ¤íŠ¸ ìƒì„±                                | ê³ ê° ì§€ì› ì±—ë´‡, ì¸í„°ë™í‹°ë¸Œ Q&A, ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ          |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 5. ì–¸ì œ ì–´ë–¤ ê²ƒì„ ì„ íƒí•´ì•¼ í• ê¹Œìš”?\n",
    "- **ë‹¨ì¼ ì‘ì—…ì´ë‚˜ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„±**:\n",
    "  - `LLM`ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì í•©í•©ë‹ˆë‹¤.\n",
    "- **ëŒ€í™” ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ë‚˜ ë¬¸ë§¥ì„ ìœ ì§€í•´ì•¼ í•˜ëŠ” ì‘ì—…**:\n",
    "  - `Chat Model`ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì í•©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ab128-5b67-4513-bc1b-a0911d01dc39",
   "metadata": {},
   "source": [
    "# LangChain ì²« ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46f6098-b13b-45d0-a2fa-07b89a787975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.27'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d4931-6ce9-4480-9a83-2f4fc077822f",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b790b185-1e10-4e8e-8863-12eef088d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_community ëª¨ë“ˆ\n",
    "#  - LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í™•ì¥ ëª¨ë“ˆ\n",
    "#  - LangChainì˜ ê³µì‹ ì»¤ë®¤ë‹ˆí‹°ê°€ ê°œë°œí•œ ì—¬ëŸ¬ í™•ì¥ ê¸°ëŠ¥ì„ í¬í•¨í•œ ëª¨ë“ˆ\n",
    "#  - ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œë‚˜ ìœ í‹¸ë¦¬í‹°ê°€ í¬í•¨\n",
    "#  - ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ìë“¤ì´ LangChainì„ ë” ì˜ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ë„êµ¬ë“¤ì´ í¬í•¨\n",
    "#  - Colab ì—ëŠ” ê¸°ë³¸ ì„¤ì¹˜ ë˜ì–´ ìˆì§€ ì•ŠìŒ (2024.12 í˜„ì¬)\n",
    "\n",
    "#  ê³µì‹ API ë ˆí¼ëŸ°ìŠ¤ https://python.langchain.com/api_reference/community/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827dbd87-1932-4b7e-9c02-bef8147035a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain-openai ëª¨ë“ˆ\n",
    "#  - LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAIì˜ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” í™•ì¥ ëª¨ë“ˆ\n",
    "#  - OpenAI APIì™€ì˜ í†µí•©ì„ ê°„ì†Œí™”:  ì‚¬ìš©ìê°€ OpenAIì˜ ëª¨ë¸ì„ ì‰½ê²Œ í˜¸ì¶œí•˜ê³  ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í…ìŠ¤íŠ¸ ìƒì„±, ìš”ì•½, ë²ˆì—­, ì§ˆì˜ì‘ë‹µ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "#  - Chain ë° Tool Integration: ë‹¤ì–‘í•œ \"Chain\" ë° \"Tool\"ë“¤ì„ ê²°í•©í•˜ì—¬ ë³µì¡í•œ NLP ì‘ì—…ì„ ìë™í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. langchain-openai ëª¨ë“ˆì€ OpenAI ëª¨ë¸ì„ LangChainì˜ ë‹¤ë¥¸ êµ¬ì„± ìš”ì†Œì™€ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ í•´, ë‹¤ì–‘í•œ ì–¸ì–´ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "#  - â˜…ì‚¬ìš©í•˜ë ¤ë©´ í™˜ê²½ë³€ìˆ˜ì— ë°˜ë“œì‹œ OPENAI_API_KEY ê°’ì´ ìˆì–´ì•¼ í•œë‹¤\n",
    "\n",
    "#  ê³µì‹ API ë ˆí¼ëŸ°ìŠ¤ https://python.langchain.com/api_reference/openai/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5de7830-68a0-4843-b14b-051de6be1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms.base import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a21e26-5cde-4bde-b85c-c29e40e37373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.base import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60430efa-5ea2-4bae-b2fa-6a3c6d7f43a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo-instruct'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM ìƒì„±\n",
    "llm = OpenAI()    # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ì—ëŸ¬\n",
    "\n",
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dafe8ca5-32f4-462b-8dc4-66467ccc5914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat model ìƒì„±\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "chat.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447d80d-9972-44f5-a3c9-1d0f6d069970",
   "metadata": {},
   "source": [
    "## LLM í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c9cc75-c4c6-403e-ba5c-928fbfd1c25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "As of October 2021, there are eight planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, there are potentially thousands of planets in other solar systems beyond our own.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"How many planets are there?\")  # ì…ë ¥ str\n",
    "\n",
    "type(result)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78d08dae-7729-4b70-a8fa-70964266870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "í˜„ì¬ê¹Œì§€ ë°œê²¬ëœ íƒœì–‘ê³„ì˜ í–‰ì„±ì€ 8ê°œì´ë©°, íƒœì–‘ê³„ ì™¸ê³½ì—ëŠ” ì†Œí–‰ì„±ì´ë‚˜ ì™œí–‰ì„± ë“± ë‹¤ì–‘í•œ ë¬¼ì²´ë“¤ë„ ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"íƒœì–‘ê³„ì—ëŠ” ì–¼ë§ˆë‚˜ ë§ì€ í–‰ì„±ë“¤ì´ ìˆë‚˜ìš”?\")  # ì…ë ¥ str\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff800d13-d986-4801-9753-7112e47012c2",
   "metadata": {},
   "source": [
    "## ChatModel í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9679d75e-7881-4570-b788-608032cb2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’š content='There are 8 officially recognized planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. The status of Pluto as a planet remains debated among scientists and astronomers.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 13, 'total_tokens': 57, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CXli5w3h5tQiLXSyGVBRAi6bHoIUd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--faad138b-6d9d-4b2b-9086-980e84ab300c-0' usage_metadata={'input_tokens': 13, 'output_tokens': 44, 'total_tokens': 57, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "ğŸ§¡ë‹µë³€ There are 8 officially recognized planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. The status of Pluto as a planet remains debated among scientists and astronomers.\n"
     ]
    }
   ],
   "source": [
    "result = chat.invoke(\"How many planets are there?\")  # ì…ë ¥ìœ¼ë¡œ ê± str ë„ ê°€ëŠ¥.\n",
    "\n",
    "type(result)  # Message ê°ì²´ \n",
    "\n",
    "print('ğŸ’š', result)\n",
    "print('ğŸ§¡ë‹µë³€', result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761e03ea-2d5e-4230-a38d-c1564d88a1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’š content='íƒœì–‘ê³„ì—ëŠ” ìˆ˜ì„±, ê¸ˆì„±, ì§€êµ¬, í™”ì„±, ëª©ì„±, í† ì„±, ì²œì™•ì„±, í•´ì™•ì„±, ê·¸ë¦¬ê³  ê·¸ë“¤ì˜ ìœ„ì„±ë“¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” ëª…ì™•ì„±ê³¼ ëª…ì™•ì„± ì´í›„ì˜ ì†Œí–‰ì„±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. detritusë¥¼ í¬í•¨í•˜ê¸°ë„ í•©ë‹ˆë‹¤.ìœ„ì„±ë©ì–´ë¦¬ ê°™ì€ ì˜¤ë¸Œì íŠ¸ë„ ë‹¨ì¼ì ìœ¼ë¡œ ë˜ì–´ìˆê±°ë‚˜, ë§¤ìš° ë¹ ë¥¸ ìˆœí™˜ìœ¼ë¡œ ëŒì•„ì™€ ë°”ë¡œ ë°”ê¹¥ê³„ ì™¸ê³„ì¬ ì™¸ê³„ì¬ í˜¼ë€ ë¤ ìŒì„±ìœ¼ë¡œ ê·¸ë¦¬ë¡œ ì •ì˜ì§€ì€ í•´ì‹ ê³„ ê·¸ë˜ì„œ ì´ ì—ì„œ ìš°ì£¼ ì¢‹ì€ ë˜ ë°±ê°€ì¡±í–ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 205, 'prompt_tokens': 28, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CXli73CWVUXISGXHYnEwqRBkZhgD9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--881dffee-2322-4f49-92c4-f68cf37f8ac5-0' usage_metadata={'input_tokens': 28, 'output_tokens': 205, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "ğŸ§¡ë‹µë³€ íƒœì–‘ê³„ì—ëŠ” ìˆ˜ì„±, ê¸ˆì„±, ì§€êµ¬, í™”ì„±, ëª©ì„±, í† ì„±, ì²œì™•ì„±, í•´ì™•ì„±, ê·¸ë¦¬ê³  ê·¸ë“¤ì˜ ìœ„ì„±ë“¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” ëª…ì™•ì„±ê³¼ ëª…ì™•ì„± ì´í›„ì˜ ì†Œí–‰ì„±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. detritusë¥¼ í¬í•¨í•˜ê¸°ë„ í•©ë‹ˆë‹¤.ìœ„ì„±ë©ì–´ë¦¬ ê°™ì€ ì˜¤ë¸Œì íŠ¸ë„ ë‹¨ì¼ì ìœ¼ë¡œ ë˜ì–´ìˆê±°ë‚˜, ë§¤ìš° ë¹ ë¥¸ ìˆœí™˜ìœ¼ë¡œ ëŒì•„ì™€ ë°”ë¡œ ë°”ê¹¥ê³„ ì™¸ê³„ì¬ ì™¸ê³„ì¬ í˜¼ë€ ë¤ ìŒì„±ìœ¼ë¡œ ê·¸ë¦¬ë¡œ ì •ì˜ì§€ì€ í•´ì‹ ê³„ ê·¸ë˜ì„œ ì´ ì—ì„œ ìš°ì£¼ ì¢‹ì€ ë˜ ë°±ê°€ì¡±í–ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "result = chat.invoke(\"íƒœì–‘ê³„ì—ëŠ” ì–´ë–¤ í–‰ì„±ë“¤ì´ ìˆë‚˜ìš”?\")  # ì…ë ¥ìœ¼ë¡œ ê± str ë„ ê°€ëŠ¥.\n",
    "\n",
    "type(result)  # Message ê°ì²´ \n",
    "\n",
    "print('ğŸ’š', result)\n",
    "print('ğŸ§¡ë‹µë³€', result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbbeb7e-9f54-47b7-8cbb-62a8e033cf4d",
   "metadata": {},
   "source": [
    "## í•œê¸€ or ì˜ì–´ ?\n",
    "\n",
    "ì±— GPTì˜ ì–¸ì–´ ì²˜ë¦¬ ëŠ¥ë ¥ì€ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ í›Œë¥­í•œ ë°œì „ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‚¬ìš©ìê°€ ë°›ëŠ” ë‹µë³€ì˜ í’ˆì§ˆì€ ì œì¶œí•˜ëŠ” ì–¸ì–´ì— ë”°ë¼ ì•½ê°„ì˜ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ì°¨ì´ëŠ” ì±— GPTê°€ í•™ìŠµí•˜ëŠ” ê³¼ì •ì—ì„œ ë‹¤ì–‘í•œ ì–¸ì–´ì˜ ë°ì´í„° ì–‘ê³¼ í’ˆì§ˆ, ê·¸ë¦¬ê³  ì–¸ì–´ë³„ íŠ¹ì„±ì„ ì–¼ë§ˆë‚˜ ì˜ ì²˜ë¦¬í•˜ëŠ”ì§€ì— ë”°ë¼ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "\n",
    "OpenAIì˜ ì–¸ì–´ ëª¨ë¸, íŠ¹íˆ GPT ì‹œë¦¬ì¦ˆëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì–»ì€ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¡œ í•™ìŠµë©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ì£¼ë¡œ ì˜ì–´ë¥¼ ë¹„ë¡¯í•œ ì—¬ëŸ¬ ì–¸ì–´ì—ì„œ ìˆ˜ì§‘ë˜ë©°, í•™ìŠµ ë°ì´í„°ì˜ êµ¬ì„±ì€ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì¼ë°˜í™” ëŠ¥ë ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ì–´ëŠ” ì „ì„¸ê³„ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ë©°*, ì¸í„°ë„· ìƒì˜ ë°ì´í„°ë„ ì˜ì–´ê°€ ë§ì•„ì„œ ì±— GPTëŠ” ì˜ì–´ ì§ˆë¬¸ì— ëŒ€í•´ ë” ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì œê³µí•  í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í•œêµ­ì–´ì™€ ê°™ì€ ë‹¤ë¥¸ ì–¸ì–´ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, ì–¸ì–´ì˜ ë³µì¡ì„± ë•Œë¬¸ì— ì²˜ë¦¬ê°€ ë” ì–´ë ¤ìš¸ ìˆ˜ ìˆì–´, ì´ë¡œ ì¸í•´ ë‹µë³€ì˜ í’ˆì§ˆì— ì°¨ì´ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì°¸ê³ \n",
    "- https://fastcampus.co.kr/gov_review_insightGPTlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857fa05-460b-45a4-8523-4d04bfca0e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35fe14d-9275-4d1e-82aa-9c6f36e7221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•„ë˜ì™€ ê°™ì´ api í‚¤ë¥¼ ì§ì ‘ ë§¤ê°œë³€ìˆ˜ë¡œ ê±´ë„¤ì¤„ìˆ˜ë„ ìˆì§€ë§Œ...  KEY ë¹„ì¶”í•œë‹¤.  í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©ì„ ì¶”ì²œí•œë‹¤.\n",
    "#\n",
    "# llm = OpenAI(openai_api_key=\"sk-\")\n",
    "# chat = ChatOpenAI(openai_api_key=\"sk-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79828506-4f44-499d-aa60-09d61b196877",
   "metadata": {},
   "source": [
    "## ì‚¬ìš©ëŸ‰ í™•ì¸ í•´ë³´ê¸°\n",
    "ì´ì¯¤ì—ì„œ openai í˜ì´ì§€\n",
    "DASHBOARD > Usage > Activity ë¥¼ í™•ì¸í•´ë³´ì.\n",
    "ì‚¬ìš©í•œ ì–‘ì´ í‘œì‹œë ê±°ë‹¤.\n",
    "\n",
    "https://platform.openai.com/usage/activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d78ad-9978-43ca-9fe3-005ed64f9112",
   "metadata": {},
   "source": [
    "## ë‹¤ë¥¸ LLM ëª¨ë¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b564c245-2360-4d39-b43e-00e2d56f920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic.chat_models import ChatAnthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14082c-9401-447c-9b14-9d73bb29feb2",
   "metadata": {},
   "source": [
    "# â–  Invoke Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d2f6e9-7be3-45ff-b77f-c3cfcdc97a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatModel ì€ 'ì§ˆë¬¸'ë§Œ ë°›ëŠ”ê²Œ ì•„ë‹ˆë¼ 'ëŒ€í™”' ë„ í• ìˆ˜ ìˆë‹¤ (Message ë¥¼ ë³´ë‚¼ìˆ˜ë„ ìˆë‹¤)\n",
    "# 'ëŒ€í™”(conversation)' ì€\n",
    "#    : ì—¬ëŸ¬ ë©”ì„¸ì§€ ë¬¶ìŒ\n",
    "#    : ìƒëŒ€ì˜ ëŒ€í™”ì˜ ë§¥ë½ì— ë§ê²Œ ëŒ€ë‹µí• ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a37250b8-b055-43f7-8399-b9097d94d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/chat/openai/#instantiation\n",
    "# ë ˆí¼ëŸ°ìŠ¤ : https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html\n",
    "\"\"\"\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "        # ëª¨ë¸ì˜ ì‘ë‹µ ë‹¤ì–‘ì„±ì„ ì œì–´í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "        # ì´ëŠ” OpenAIì˜ GPT ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ë¡œ,\n",
    "        #  ìƒì„±ë˜ëŠ” í…ìŠ¤íŠ¸ì˜ ì°½ì˜ì„±ê³¼ í™•ë¥ ì  ë‹¤ì–‘ì„±(ëœë¤ì„±ì„ ì¡°ì •í•©ë‹ˆë‹¤)ã„´\n",
    "        #\n",
    "    max_tokens=None,  # modelì´ ë¦¬í„´í•˜ëŠ” ê²°ê³¼ì˜ ìµœëŒ€ token ê°œìˆ˜ì§€ì •.\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "092024a1-fc46-4b54-b8c6-83ec6e49bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ad143-96fd-4a72-93e2-fc0e07f7daf0",
   "metadata": {},
   "source": [
    "## Human / System / AI Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f54195fc-6a98-4e1d-b7a4-21304e31f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.messages.ai import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d1708af-74ad-48cb-b445-1833b3d0ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HumanMessage : ì‚¬ëŒì´ AI ì— ë³´ë‚´ëŠ” Message\n",
    "# SystemMessage : LLM ì— ì„¤ì •ë“¤ì„ ì œê³µí•˜ê¸° ìœ„í•œ Message\n",
    "# AIMessage: AI ì— ì˜í•´ ë¦¬í„´ë˜ëŠ” Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "030a1aad-20a0-4689-8f9c-307249ac7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content = \"You are a geography expert. And your only reply in Korean\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content = \"ì•ˆë…•, ë‚´ ì´ë¦„ì€ ë‘˜ë¦¬ì•¼\",\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content = \"\"\"What is the distance between Mexico and Thailand.\n",
    "          Also, what is your name?\"\"\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d7dd9fa-9662-457f-9453-1107fcac172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë©•ì‹œì½”ì™€ íƒœêµ­ ì‚¬ì´ì˜ ê±°ë¦¬ëŠ” ì•½ 16,000kmì…ë‹ˆë‹¤. ì œ ì´ë¦„ì€ ë‘˜ë¦¬ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 57, 'total_tokens': 92, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CXlnEcBKJ23Z2WUcZZJaP9MHZZHCw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1d4b978c-f171-41fe-993c-16e2246118b6-0', usage_metadata={'input_tokens': 57, 'output_tokens': 35, 'total_tokens': 92, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat.invoke(messages)  # <- ì…ë ¥ Messages\n",
    "\n",
    "print(type(result)) # AIMessage\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6364a-9719-4588-b2d1-4aac3d8c9130",
   "metadata": {},
   "source": [
    "# â–  Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76980b72-05cd-47e2-9d6d-700f56d93dd7",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "â†‘ messages ë¥¼ prompt ë¼ê³ ë„ í•¨ (?)\n",
    "- ëª¨ë¸ì— ì…ë ¥ìœ¼ë¡œ ì œê³µë˜ëŠ” í…ìŠ¤íŠ¸ë‚˜ ë°ì´í„°\n",
    "- ëª¨ë¸ì—ê²Œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ì§€ì‹œí•˜ê±°ë‚˜, ëª¨ë¸ì´ ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µ\n",
    "- LLM ê³¼ ì˜ì‚¬ì†Œí†µí•˜ê¸° ìœ„í•œ ë°©ë²•\n",
    "\n",
    "---\n",
    "\n",
    "LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸)ì—ì„œ **í”„ë¡¬í”„íŠ¸ prompt**ë€ ëª¨ë¸ì— **ì…ë ¥**ìœ¼ë¡œ ì œê³µë˜ëŠ” í…ìŠ¤íŠ¸ë‚˜ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì—ê²Œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ì§€ì‹œí•˜ê±°ë‚˜, ëª¨ë¸ì´ ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì˜ ì¶œë ¥ì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í”„ë¡¬í”„íŠ¸ì˜ ì—­í• :\n",
    "1. **ëª¨ë¸ì— ëŒ€í•œ ì§€ì‹œ**: í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì—ê²Œ ë¬´ì—‡ì„ í•´ì•¼ í• ì§€ ì•Œë ¤ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ ëª¨ë¸ì—ê²Œ ì§ˆë¬¸ì„ í•˜ê±°ë‚˜, íŠ¹ì • ìŠ¤íƒ€ì¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•  ë•Œ í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. **ì»¨í…ìŠ¤íŠ¸ ì œê³µ**: ëª¨ë¸ì´ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•„ìš”í•œ ë°°ê²½ ì •ë³´ë‚˜ ë¬¸ë§¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–´ë–¤ ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì„ í•  ë•Œ, ê´€ë ¨ ë°°ê²½ ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ ëª¨ë¸ì´ ë” ì •í™•í•œ ë‹µì„ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. **ëª¨ë¸ì˜ ì¶œë ¥ ìœ ë„**: í”„ë¡¬í”„íŠ¸ê°€ ëª¨ë¸ì˜ ì¶œë ¥ì„ ìœ ë„í•˜ê³ , ìƒì„±ë˜ëŠ” í…ìŠ¤íŠ¸ì˜ ìŠ¤íƒ€ì¼, ë‚´ìš©, í˜•ì‹ ë“±ì„ ê²°ì •í•˜ëŠ” ë° ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n",
    "\n",
    "### ì˜ˆì‹œ:\n",
    "1. **ì§ˆë¬¸ ì‘ë‹µ**:\n",
    "   - **í”„ë¡¬í”„íŠ¸**: \"What is the capital of France?\"\n",
    "   - **ì¶œë ¥**: \"The capital of France is Paris.\"\n",
    "\n",
    "2. **ì°½ì˜ì  ê¸€ì“°ê¸°**:\n",
    "   - **í”„ë¡¬í”„íŠ¸**: \"Write a short story about a dragon and a knight.\"\n",
    "   - **ì¶œë ¥**: ëª¨ë¸ì´ ì°½ì˜ì ìœ¼ë¡œ ë“œë˜ê³¤ê³¼ ê¸°ì‚¬ì— ê´€í•œ ì´ì•¼ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. **ë²ˆì—­**:\n",
    "   - **í”„ë¡¬í”„íŠ¸**: \"Translate the following sentence to Spanish: 'Hello, how are you?'\"\n",
    "   - **ì¶œë ¥**: \"Hola, Â¿cÃ³mo estÃ¡s?\"\n",
    "\n",
    "### í”„ë¡¬í”„íŠ¸ì˜ ì¢…ë¥˜:\n",
    "- **ë‹¨ìˆœí•œ ì§ˆë¬¸**: ì‚¬ìš©ìê°€ ë‹¨ìˆœíˆ ê¶ê¸ˆí•œ ì ì„ ë¬»ëŠ” í˜•íƒœ.\n",
    "- **ì§€ì‹œë¬¸**: íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ì§€ì‹œí•˜ëŠ” í˜•íƒœ.\n",
    "- **í˜•ì‹í™”ëœ ì…ë ¥**: íŠ¹ì • í˜•ì‹ì´ë‚˜ êµ¬ì¡°ë¥¼ ê°–ì¶˜ ì…ë ¥(ì˜ˆ: í…ìŠ¤íŠ¸ ìš”ì•½, ë²ˆì—­, ì½”ë“œ ì‘ì„± ë“±).\n",
    "\n",
    "### í”„ë¡¬í”„íŠ¸ ì„¤ê³„ì˜ ì¤‘ìš”ì„±:\n",
    "- **ì •í™•í•œ ê²°ê³¼**ë¥¼ ì–»ê¸° ìœ„í•´ì„œëŠ” **í”„ë¡¬í”„íŠ¸ì˜ ì„¤ê³„**ê°€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ê°€ ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•˜ë©´ ëª¨ë¸ì´ ì›í•˜ëŠ” ì¶œë ¥ì„ ìƒì„±í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n",
    "- ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹¤í—˜í•˜ë©´ì„œ ëª¨ë¸ì˜ ë°˜ì‘ì„ ê´€ì°°í•˜ê³ , ê°€ì¥ ì í•©í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í”„ë¡¬í”„íŠ¸ ì„¤ê³„ íŒ:\n",
    "1. **ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì§€ì‹œ**: ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, \"Explain quantum mechanics\"ë³´ë‹¤ëŠ” \"Explain quantum mechanics in simple terms for a high school student\"ì™€ ê°™ì´ êµ¬ì²´ì ì¸ ìš”êµ¬ë¥¼ í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "   \n",
    "2. **ì ì ˆí•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ**: í•„ìš”í•œ ë°°ê²½ ì •ë³´ë‚˜ ë¬¸ë§¥ì„ ì œê³µí•˜ë©´ ëª¨ë¸ì´ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "3. **ë‹¤ì–‘í•œ ì‹¤í—˜**: í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ê¸ˆì”© ë°”ê¿”ê°€ë©° í…ŒìŠ¤íŠ¸í•´ ë³´ë©´ì„œ ìµœì ì˜ ì‘ë‹µì„ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ê²°ë¡ :\n",
    "í”„ë¡¬í”„íŠ¸ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì—ê²Œ ì‘ì—…ì„ ì§€ì‹œí•˜ëŠ” ì¤‘ìš”í•œ ì…ë ¥ìœ¼ë¡œ, ëª¨ë¸ì´ ìˆ˜í–‰í•  ì‘ì—…ì˜ ë°©í–¥ì„ ê²°ì •ì§“ëŠ” ìš”ì†Œì…ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ ì„¤ê³„í•˜ëŠ” ê²ƒì´ LLMì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë° í° ë„ì›€ì´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84612367-d02a-40ba-a956-04d8df318cb9",
   "metadata": {},
   "source": [
    "Prompt ì„±ëŠ¥ì´ ì¢‹ë‹¤ë©´ LLM ë‹µë³€ì˜ ì„±ëŠ¥ë„ ì¢‹ì„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë“  ì›¹ ì‚¬ì´íŠ¸ë“¤ì€ ìƒí™©ì— ë§ëŠ” ë›°ì–´ëŠ” ì„±ëŠ¥ì˜ prompt ë¥¼ ì œì‘í•˜ëŠ”ë° ì „ë…í•¨.\n",
    "\n",
    "LangChain ì€ prompt ë¥¼ ê³µìœ í•˜ê¸° ìœ„í•œ ì»¤ë®¤ë‹ˆí‹°ë„ í˜•ì„±ë˜ê³  ìˆë‹¤.\n",
    "ì‚°ì—… ì „ì²´ ì „ë°˜ì ìœ¼ë¡œ ê° ë¶„ì•¼ë³„ prompt ë¥¼ ë§Œë“¤ì–´ ë‚´ê³  ìˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ë©´\n",
    "| í”Œë«í¼               | ê¸°ëŠ¥              | URL                                                             |\n",
    "| ----------------- | --------------- | --------------------------------------------------------------- |\n",
    "| **LangChain Hub** | í”„ë¡¬í”„íŠ¸ ë° ì²´ì¸ ê³µìœ     | [smith.langchain.com/hub](https://smith.langchain.com/hub)      |\n",
    "| **Discord**       | ì»¤ë®¤ë‹ˆí‹°, í”„ë¡¬í”„íŠ¸ ë…¼ì˜   | [discord.gg/langchain](https://discord.gg/langchain)            |\n",
    "| **GitHub**        | ì½”ë“œ ì˜ˆì œ, í”„ë¡¬í”„íŠ¸ í™œìš©ë²• | [LangChain Examples](https://github.com/langchain-ai/langchain) |\n",
    "\n",
    "\n",
    "ê·¸ë˜ì„œ, LangChain í”„ë ˆì„ì›Œí¬ì˜ ë§ì€ ë¶€ë¶„ì´ prompt ì— ì§‘ì¤‘ë˜ì–´ ìˆë‹¤.\n",
    "\n",
    "prompt ë¼ë¦¬ ê²°í•¨ë„ í• ìˆ˜ ìˆê³ , ì €ì¥í•˜ê±°ë‚˜ ë¶ˆëŸ¬ì˜¬ìˆ˜ë„ ìˆë‹¤.\n",
    "\n",
    "ë³€ìˆ˜ ì„¤ì • ë„ì¤‘ì— ê²€ì¦ë„ í• ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae825204-2248-4768-8934-6d978125ebeb",
   "metadata": {},
   "source": [
    "## PromptTemplate\n",
    "ë©”ì‹œì§€ ì»¤ìŠ¤í„°ë§ˆì´ì§• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1b5a47-3b09-46bb-800f-4815d51e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.prompts.chat import ChatMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9866636a-f884-465f-beed-c6125cca650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplate ëŠ” message(s) ë¡œë¶€í„° template ì„ ë§Œë“¬.\n",
    "# PromptTemplate ëŠ” string ì„ ì´ìš©í•´ì„œ template ì„ ë§Œë“¬.\n",
    "#  â†‘ ë‘˜ë‹¤ ìœ ìš©í•˜ê²Œ ì“°ì„."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0f531d1-d25c-4300-af5f-f414328cfe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country_a', 'country_b'], input_types={}, partial_variables={}, template='What is the distance between {country_a} and {country_b}')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\n",
    "    # placeholder {...} ì‚¬ìš©\n",
    "    \"What is the distance between {country_a} and {country_b}\"\n",
    ")\n",
    "\n",
    "print(type(template))\n",
    "\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7527e3f7-1e48-47c7-80d5-c27904690dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template.format()  # KeyError: 'country_a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a00eea97-7ab7-4691-afd7-f453dea34d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the distance between Mecixo and Thailand'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = template.format(country_a=\"Mecixo\",country_b=\"Thailand\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2db174b0-a648-4393-9c5b-67517989940d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles) when measured in a straight line. However, the actual distance may vary depending on the specific locations within each country and the mode of transportation used.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 17, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CXlzSvv6HRkIB18kvvVnC7w8PctFq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9f709d5e-1238-4ae3-a84e-389a6a28aa4a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 48, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22fd544-5445-4262-bee0-16ab67603758",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc66d808-9e3b-4063-b8db-77169e0a652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country_a', 'country_b', 'language', 'name'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a geography expert. And your only reply in {language}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='ì•ˆë…•, ë‚´ ì´ë¦„ì€ {name} ì•¼'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country_a', 'country_b'], input_types={}, partial_variables={}, template='\\n        What is the distance between {country_a} and {country_b}.\\n        Also, what is your name?    \\n    '), additional_kwargs={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    # SystemMessage íŠœí”Œ\n",
    "    (\"system\", \"You are a geography expert. And your only reply in {language}\"),\n",
    "    # AIMessage íŠœí”Œ \n",
    "    (\"ai\", \"ì•ˆë…•, ë‚´ ì´ë¦„ì€ {name} ì•¼\"),\n",
    "\n",
    "    # HumanMessage íŠœí”Œ\n",
    "    (\"human\", \"\"\"\n",
    "        What is the distance between {country_a} and {country_b}.\n",
    "        Also, what is your name?    \n",
    "    \"\"\"),  \n",
    "])\n",
    "\n",
    "print(type(template))\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc7c5fe6-e865-492b-b510-2057fbd4dfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a geography expert. And your only reply in Korean', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…•, ë‚´ ì´ë¦„ì€ ë½€ë¡œë¡œ ì•¼', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='\\n        What is the distance between Canada and Japan.\\n        Also, what is your name?    \\n    ', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = template.format_messages(\n",
    "    language=\"Korean\",\n",
    "    name=\"ë½€ë¡œë¡œ\",\n",
    "    country_a = \"Canada\",\n",
    "    country_b = \"Japan\",\n",
    ")\n",
    "\n",
    "print(type(prompt))\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c05bec58-b680-4a14-be4b-43e7295e569c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ìºë‚˜ë‹¤ì™€ ì¼ë³¸ ì‚¬ì´ì˜ ê±°ë¦¬ëŠ” ì•½ 7,000kmì…ë‹ˆë‹¤. ì œ ì´ë¦„ì€ ë½€ë¡œë¡œì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 63, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CXm7zxSloRr9fX8NDrNF53gba16hw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c1c8902-efb7-439d-8545-398aa3a6a43b-0', usage_metadata={'input_tokens': 63, 'output_tokens': 35, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567669f8-6a9f-4e35-8192-0d7f43a6dd4e",
   "metadata": {},
   "source": [
    "# â–  OutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ff779-dfdc-4af3-ae41-de3aad7bdb27",
   "metadata": {},
   "source": [
    "## Output Parser ë€\n",
    "\n",
    "LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸)ì—ì„œ ìƒì„±ëœ ì¶œë ¥ì„ ì²˜ë¦¬í•˜ê³  'ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜'í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ìœ í‹¸ë¦¬í‹°ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ 'êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜'í•˜ê±°ë‚˜, 'íŠ¹ì • ê·œì¹™ì— ë”°ë¼ ë°ì´í„°ë¥¼ ì¶”ì¶œ'í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "1. ì¶œë ¥ êµ¬ì¡°í™”\n",
    "    - ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ JSON, ë”•ì…”ë„ˆë¦¬, ëª©ë¡ ë“±ê³¼ ê°™ì€ í”„ë¡œê·¸ë˜ë°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤\n",
    "    \n",
    "1. ì¶œë ¥ ê²€ì¦\n",
    "    - ëª¨ë¸ì´ ì˜ˆìƒì¹˜ ëª»í•œ ì¶œë ¥ì„ ë°˜í™˜í•  ê²½ìš° ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì œê³µí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ì„ ë°˜í™˜í•˜ë„ë¡ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    \n",
    "1. ì¶œë ¥ í‘œì¤€í™”\n",
    "    - ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì´ í•­ìƒ ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ì œê³µë˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41c86d-602e-433f-9030-1935b49b317d",
   "metadata": {},
   "source": [
    "## BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af7bdfc5-84b4-452d-9228-256f78585d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.base import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b89109a5-95df-4b03-a20e-a6cd735e68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaOutputParser(BaseOutputParser):\n",
    "\n",
    "    # parse() ë©”ì†Œë“œë¥¼ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼ í•œë‹¤\n",
    "    #   text=  ì…ë ¥í…ìŠ¤íŠ¸\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(',')\n",
    "        return list(map(str.strip, items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f21d0d91-632c-4db3-85b9-7563c5954f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = CommaOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a97b52e7-135f-42f2-a0e2-0dccd7b71188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë™ì‘í™•ì¸\n",
    "p.parse(\"hello,   how,   are,  you    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc92d735-5710-4e3c-8075-a2be800954de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Mercury\\n2. Venus\\n3. Earth\\n4. Mars\\n5. Jupiter\\n6. Saturn\\n7. Uranus\\n8. Neptune'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        You are a list generating machine.\n",
    "        Everything you are asked will be answered with a list of max {max_items}.\n",
    "        Do NOT reply with anything else.    \n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the planets?\",\n",
    ")\n",
    "\n",
    "result = chat.invoke(prompt)\n",
    "\n",
    "result.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cee04091-4a91-425a-ac89-35cf97ce754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Mercury\n",
      "2. Venus\n",
      "3. Earth\n",
      "4. Mars\n",
      "5. Jupiter\n",
      "6. Saturn\n",
      "7. Uranus\n",
      "8. Neptune\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cf80b7d-da74-483c-912c-dc80c15fe0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune\n"
     ]
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        You are a list generating machine.\n",
    "        Everything you are asked will be answered with a comma separated list of max {max_items}.\n",
    "        Do NOT reply with anything else.    \n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the planets?\",\n",
    ")\n",
    "\n",
    "result = chat.invoke(prompt)\n",
    "\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46222168-e14f-4bbb-8482-8802e38c2f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red, blue, green, yellow, orange, purple, pink, black, white, brown\n"
     ]
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        You are a list generating machine.\n",
    "        Everything you are asked will be answered with a comma separated list of max {max_items}.\n",
    "        Do NOT reply with anything else.    \n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the colors?\",\n",
    ")\n",
    "\n",
    "result = chat.invoke(prompt)\n",
    "\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f20f6cc6-e8c2-4d3c-92d4-82e72db51f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red, blue, green, yellow, orange, purple, pink, black, white, brown\n"
     ]
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        You are a list generating machine.\n",
    "        Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase.\n",
    "        Do NOT reply with anything else.    \n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the colors?\",\n",
    ")\n",
    "\n",
    "result = chat.invoke(prompt)\n",
    "\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdee5b97-ff64-4071-9055-91fa3bffc923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        You are a list generating machine.\n",
    "        Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase.\n",
    "        Do NOT reply with anything else.    \n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the colors?\",\n",
    ")\n",
    "\n",
    "result = chat.invoke(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4f558-a7f5-4d20-85a6-cb664245cccc",
   "metadata": {},
   "source": [
    "# â–  Chain, LCEL\n",
    "\n",
    "- LCEL (LangChain Expression Language: ë­ì²´ì¸ í‘œí˜„ ì–¸ì–´)\n",
    "  - LCELì€ LangChain ë‚´ì—ì„œ ë³µì¡í•œ í‘œí˜„ì‹ì„ ì²˜ë¦¬í•˜ê³ ,\n",
    "  - ëª¨ë¸ê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ ë” ê°•ë ¥í•˜ê³  ìœ ì—°í•˜ê²Œ ë§Œë“œëŠ” ê¸°ëŠ¥ì„ ì œê³µ\n",
    "    - ì½”ë“œì–‘ì„ ë§ì´ ì¤„ì—¬ì¤Œ.\n",
    "    - ë‹¤ì–‘í•œ template ê³¼ LLM í˜¸ì¶œ\n",
    "    - ì„œë¡œ ë‹¤ë¥¸ ì‘ë‹µ(response) ë¥¼ í•¨ê»˜ ì‚¬ìš©ì¼€ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da758fff-3134-4c73-8fb1-52d756a04eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain ì´ë¼ëŠ” ê²ƒì€ ê¸°ë³¸ì ìœ¼ë¡œ, ëª¨ë“  ìš”ì†Œë¥¼ ì—°ê²°í•´ì£¼ëŠ”(í•©ì³ì£¼ëŠ”) ì—­í• ì„ í•¨.\n",
    "# í•©ì³ì§„ ìš”ì†Œë“¤ì€ í•˜ë‚˜ì˜ chain ìœ¼ë¡œ ì‹¤í–‰ë ê²ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8cfda98-7ee7-4e9e-a680-0539f6d4d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['max_items', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['max_items'], input_types={}, partial_variables={}, template='\\n        You are a list generating machine.\\n        Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase.\\n        Do NOT reply with anything else.    \\n    '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000016F2F4C4650>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000016F2F4C4BC0>, root_client=<openai.OpenAI object at 0x0000016F2DD3E000>, root_async_client=<openai.AsyncOpenAI object at 0x0000016F2F4C47A0>, temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| CommaOutputParser()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain ìƒì„±\n",
    "# '|' ì—°ì‚°ì ì‚¬ìš©\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "print(type(chain))  # RunnableSequence\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76626bcc-99a5-49ff-8ce9-383989288721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charmander', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "chain.invoke({\n",
    "    'max_items': 5,\n",
    "    'question': 'What are the pokemons?',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c813e0-c72c-4365-8ee2-f69498091355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â†‘ Chain ì„ ì‚¬ìš©í•´ ê½¤ë‚˜ ê°„ê²°í•œ ì½”ë“œë¡œ ì‘ë™ëœë‹¤!\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke({...})\n",
    "ì‚¬ì‹¤ ë­ì²´ì¸ì€ ë‚´ë¶€ì—ì„œ\n",
    "  .format_message() í˜¸ì¶œ -> prompt ì™„ì„±\n",
    "  -> chat.invoke() í˜¸ì¶œ -> AIMessage ë¦¬í„´\n",
    "  -> parse() í˜¸ì¶œí•œë‹¤\n",
    "\n",
    "ì´ëŸ¬í•œ ì¼ë ¨ì˜ ì‘ì—…ì„ chain.invoke() í˜¸ì¶œ ë‹¨í•œë²ˆìœ¼ë¡œ ëë‚¸ë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ chain êµ¬ë¬¸ìœ¼ë¡œ ì •ë§ ë‹¤ì–‘í•œ ì‘ì—…ì˜ íë¦„ë“¤ì„ ìˆ˜í–‰í• ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c60b65-0e33-48e8-8aa6-171155b3fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "chain ë¼ë¦¬ë„ ê²°í•©í• ìˆ˜ ë„ ìˆë‹¤.\n",
    "\n",
    "[ì˜ˆì‹œ]\n",
    "chain_one = template | chat | CommaOutputParser()\n",
    "chain_two = template_2 | chat | OutputParser2()\n",
    "\n",
    "all = chain_one | chain_two | OutputParser3()\n",
    "  â†‘ chain_one ì˜ ì¶œë ¥ì„ chain_two ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥.\n",
    "\"\"\"\n",
    "None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5380ed-9d8f-4283-a5a2-29f62f877977",
   "metadata": {},
   "source": [
    "# â–  Chaining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dcbe65-9d37-433a-b268-f6344e28ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë­ì²´ì¸ ëŒ€ì‹  OpenAI api ë¥¼ ì‚¬ìš©í•œë‹¤ë©´ ì—ì„œ gpt-3.5-turbo ì—ê²Œì„œ ì‘ë‹µ ë°›ëŠ” ë°©ë²•ì€ ëŒ€ì²´ë¡œ ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "# https://platform.openai.com/docs/guides/text-generation\n",
    "\n",
    "\"\"\"\n",
    "# from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6abe69-3360-45f2-ac57-5136c706cf7b",
   "metadata": {},
   "source": [
    "## LCEL ì˜ input / output\n",
    "\n",
    "LangChain Expression Language (LCEL)ì€ LangChainì—ì„œ ë‹¤ì–‘í•œ ì…ë ¥ ìœ í˜•ì„ í™œìš©í•˜ì—¬ LLMê³¼ ë„êµ¬ë¥¼ ê²°í•©í•˜ê³  ë°ì´í„° íë¦„ì„ ì œì–´í•˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤. LCELì€ LLMì˜ ì…ë ¥ê³¼ ì²˜ë¦¬ì— ì‚¬ìš©ë˜ëŠ” **ì…ë ¥ íƒ€ì…**(Input Types)ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•˜ì—¬, ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ì™€ ë„êµ¬ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” LCELì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” **ì…ë ¥ íƒ€ì…**ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Plain Text**\n",
    "- **ì„¤ëª…**: ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ì…ë ¥ì…ë‹ˆë‹¤. ì´ í˜•ì‹ì€ ê°€ì¥ ê¸°ë³¸ì ì¸ ì…ë ¥ìœ¼ë¡œ, LLMì´ ììœ ë¡œìš´ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```plaintext\n",
    "  What is the capital of France?\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - í…ìŠ¤íŠ¸ ë¶„ì„, ìƒì„± ë° ëŒ€í™”í˜• ì‘ì—…ì— ì í•©.\n",
    "  - ì¶”ê°€ì ì¸ êµ¬ì¡°ë‚˜ ë©”íƒ€ë°ì´í„° ì—†ì´ ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Structured Input**\n",
    "- **ì„¤ëª…**: JSON, ë”•ì…”ë„ˆë¦¬, ë˜ëŠ” êµ¬ì¡°í™”ëœ í˜•ì‹ì˜ ì…ë ¥ì…ë‹ˆë‹¤. ë°ì´í„° í•„ë“œê°€ ëª…ì‹œì ìœ¼ë¡œ ì •ì˜ë˜ì–´ ìˆìœ¼ë©°, ëª¨ë¸ì´ ì´ êµ¬ì¡°ì— ë”°ë¼ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```json\n",
    "  {\n",
    "      \"question\": \"What is the capital of France?\",\n",
    "      \"context\": \"France is a country in Europe.\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - ëª…ì‹œì ì¸ ë°ì´í„° í•„ë“œë¥¼ í†µí•´ LLMì´ í•„ìš”í•œ ì •ë³´ë¥¼ ë” ì •í™•íˆ ì¶”ì¶œ ë° í™œìš© ê°€ëŠ¥.\n",
    "  - ë³µì¡í•œ ë°ì´í„° ë¶„ì„ì´ë‚˜ ë©€í‹° í•„ë“œ ì²˜ë¦¬ê°€ í•„ìš”í•œ ì‘ì—…ì— ìœ ìš©.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Prompt Templates**\n",
    "- **ì„¤ëª…**: ì‚¬ìš©ìê°€ ì •ì˜í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. í…œí”Œë¦¿ì— ë³€ìˆ˜ ê°’ì„ ì±„ì›Œ ë„£ì–´ ëª¨ë¸ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```python\n",
    "  template = \"Translate the following text to French: {text}\"\n",
    "  input = template.format(text=\"Hello, how are you?\")\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - ë³€ìˆ˜ ê¸°ë°˜ ì…ë ¥ì„ í†µí•´ ì¬ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ìŒ.\n",
    "  - ì‚¬ìš©ì ì •ì˜ ì…ë ¥ ìƒì„± ë° ì œì–´ì— ì í•©.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Key-Value Pairs**\n",
    "- **ì„¤ëª…**: í‚¤-ê°’ ìŒì˜ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ, ëª…ì‹œì ì¸ ì¿¼ë¦¬ í˜•íƒœë¡œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```python\n",
    "  {\n",
    "      \"name\": \"John\",\n",
    "      \"age\": 30,\n",
    "      \"location\": \"New York\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - ì •í˜•í™”ëœ ë°ì´í„°ë¥¼ ì œê³µí•˜ì—¬ LLMì´ ë” íš¨ìœ¨ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ì„ ë° ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ.\n",
    "  - íŠ¹ì • ì •ë³´ í•„ë“œê°€ ëª…í™•íˆ í•„ìš”í•  ë•Œ ìœ ìš©.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Multi-modal Inputs**\n",
    "- **ì„¤ëª…**: í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•ì„ ì¡°í•©í•œ ì…ë ¥ í˜•ì‹ì…ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```python\n",
    "  {\n",
    "      \"text\": \"Describe the image.\",\n",
    "      \"image\": \"<image_data>\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ê³¼ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì…ë ¥ í˜•ì‹ì„ ì²˜ë¦¬ ê°€ëŠ¥.\n",
    "  - ì´ë¯¸ì§€ ìº¡ì…”ë‹, ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸ ë³€í™˜ ë“±ì˜ ì‘ì—…ì—ì„œ í™œìš©.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Serialized Inputs**\n",
    "- **ì„¤ëª…**: ì…ë ¥ ë°ì´í„°ë¥¼ ì‹œë¦¬ì–¼í™”(Serialize)í•˜ì—¬ íŠ¹ì • í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•œ ì…ë ¥ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, JSON ë¬¸ìì—´ë¡œ ë°ì´í„°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```python\n",
    "  input = '{\"question\": \"What is the capital of France?\", \"context\": \"France is in Europe.\"}'\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - ë°ì´í„°ê°€ ì™¸ë¶€ ì‹œìŠ¤í…œì´ë‚˜ APIì™€ í†µì‹ í•  ë•Œ ìœ ìš©.\n",
    "  - ë°ì´í„° í¬ë§·ì— ëŒ€í•œ ìœ ì—°ì„±ì´ ë†’ìŒ.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Chat Messages**\n",
    "- **ì„¤ëª…**: ì±„íŒ… ë©”ì‹œì§€ í˜•ì‹ì˜ ì…ë ¥ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ì—­í• (role)ê³¼ ë‚´ìš©(content)ì„ ì •ì˜í•˜ì—¬ LLMì—ê²Œ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```python\n",
    "  [\n",
    "      {\"role\": \"system\", \"content\": \"You are an assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"What is the weather today?\"}\n",
    "  ]\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - ChatGPT ê°™ì€ ëŒ€í™”í˜• ëª¨ë¸ì— ì í•©.\n",
    "  - ëŒ€í™”ì˜ ë§¥ë½ì„ ìœ ì§€í•˜ê³  ë‹¤ì¤‘ ë°œí™” ì…ë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Custom Input Types**\n",
    "- **ì„¤ëª…**: ì‚¬ìš©ìê°€ ì• í”Œë¦¬ì¼€ì´ì…˜ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ì •ì˜í•˜ëŠ” ì»¤ìŠ¤í…€ ì…ë ¥ í˜•ì‹ì…ë‹ˆë‹¤.\n",
    "- **ì˜ˆì‹œ**:\n",
    "  ```python\n",
    "  class CustomInput:\n",
    "      def __init__(self, field1, field2):\n",
    "          self.field1 = field1\n",
    "          self.field2 = field2\n",
    "  ```\n",
    "\n",
    "- **íŠ¹ì§•**:\n",
    "  - íŠ¹ì • ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ê³¼ ì™„ë²½íˆ ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì²˜ë¦¬.\n",
    "  - í‘œì¤€ ì…ë ¥ íƒ€ì…ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ êµ¬ì¡°ë¥¼ ë‹¤ë£° ë•Œ ìœ ìš©.\n",
    "\n",
    "---\n",
    "\n",
    "### ìš”ì•½\n",
    "LCELì˜ ì…ë ¥ íƒ€ì…ì€ ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¶€í„° êµ¬ì¡°í™”ëœ ë°ì´í„°, ë©€í‹°ëª¨ë‹¬ ì…ë ¥ê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ ì œê³µë˜ë©°, ê° íƒ€ì…ì€ íŠ¹ì • ìš©ë„ì— ë§ê²Œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì…ë ¥ ë°ì´í„°ë¥¼ ì •êµí•˜ê²Œ ì„¤ê³„í•˜ê³  ì ì ˆí•œ í˜•ì‹ì„ ì„ íƒí•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d429bc-7ced-4725-a83a-fda2a7c013ed",
   "metadata": {},
   "source": [
    "## Chain ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "444f0e86-8b86-4b15-8fb5-220e99b76d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²«ë²ˆì§¸ chain\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''\n",
    "      You are a world-class international chef.\n",
    "      You create easy to follow recipes for any type of cuisines\n",
    "      with easy to find ingredients.    \n",
    "    '''),\n",
    "    ('human', '''\n",
    "        I want to cook {cuisine} food.\n",
    "    '''),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09547d0a-ceee-4c62-8a92-4553daadf6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ„ Chef ì—ê²Œì„œ ë ˆì‹œí”¼ë¥¼ ë°›ê²Œ ë í…ë°, ì´ê²Œ ì²«ë²ˆì§¸ chain ì˜ ì¶œë ¥ê²°ê³¼ë‹¤\n",
    "# ë‘ë²ˆì§¸ chain ì—ì„  ìœ„ ì¶œë ¥ê²°ê³¼ë¥¼ ì…ë ¥ë°›ì•„ì„œ 'ì±„ì‹ ì¬ë£Œ'ë§Œ ì‚¬ìš©í•˜ë„ë¡ ë³€í˜• í• ê²ë‹ˆë‹¤.\n",
    "\n",
    "# ì‘ì—…ì€ ë‘ê°œ\n",
    "#   1. ë ˆì‹œí”¼ë¥¼ ì „ë‹¬í•´ì£¼ëŠ” ì…°í”„\n",
    "#   2. ì±„ì‹ì£¼ì˜ìë¥¼ ìœ„í•œ ì…°í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06006249-974e-4049-877c-af1ede28048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ë²ˆì§¸ chain\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''\n",
    "      You are a vegetarian chef specialized on\n",
    "      making traditional recipies vegetarian.\n",
    "      You find alternative ingredients and explain their preparation.\n",
    "      You don't radically modify the recipe.\n",
    "      If there is no alternative for a food just say\n",
    "      you don't know how to replace it.    \n",
    "    '''),\n",
    "    ('human', '''{recipe}'''),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea0d80ea-1f37-4fc5-9b04-13455e8c8739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"For a vegetarian version of Chicken Tikka Masala, you can easily substitute the chicken with a plant-based alternative like tofu or paneer. Here's how you can adapt the recipe:\\n\\n**Ingredients:**\\n- 1 lb firm tofu or paneer, cut into bite-sized pieces\\n- 1 cup plain yogurt (use plant-based yogurt for a vegan option)\\n- 2 tablespoons lemon juice\\n- 2 tablespoons vegetable oil\\n- 2 tablespoons garam masala\\n- 1 tablespoon ground cumin\\n- 1 tablespoon paprika\\n- 1 tablespoon minced garlic\\n- 1 tablespoon minced ginger\\n- 1 teaspoon turmeric\\n- 1 teaspoon ground coriander\\n- 1 teaspoon chili powder (adjust to taste)\\n- Salt and pepper to taste\\n- 1 can (14 oz) tomato sauce\\n- 1 cup coconut cream (or any plant-based heavy cream)\\n- Fresh cilantro for garnish\\n- Cooked rice or naan bread for serving\\n\\n**Instructions:**\\n1. Follow the same marinating process as the original recipe, but use tofu or paneer instead of chicken. Marinate for at least 1 hour or overnight for best results.\\n   \\n2. Instead of baking the chicken, you can pan-fry or bake the marinated tofu or paneer until they are cooked through and slightly crispy.\\n   \\n3. In a large skillet, proceed with the sauce as directed in the original recipe, using tomato sauce and coconut cream (or any plant-based heavy cream) instead of dairy cream.\\n   \\n4. Add the cooked tofu or paneer to the sauce and simmer for 10 minutes to allow the flavors to blend.\\n   \\n5. Serve the Vegetarian Tikka Masala over rice or with naan bread, garnished with fresh cilantro.\\n\\nBy making these simple swaps, you can enjoy a delicious vegetarian version of Chicken Tikka Masala that's just as flavorful and satisfying!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 393, 'prompt_tokens': 779, 'total_tokens': 1172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CXn52NJhqYpaEsfd1diwOSOggg6eN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3fec8898-3f48-4619-92a2-1560f3a74c67-0', usage_metadata={'input_tokens': 779, 'output_tokens': 393, 'total_tokens': 1172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final chain\n",
    "# final_chain = chef_chain | veg_chain\n",
    "\n",
    "# chef_chain ì˜ output ì´ veg_chain ì˜ {recipe} ì…ë ¥ê°’ìœ¼ë¡œ ì „ë‹¬ë˜ê²Œ í•˜ê¸°\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "result = final_chain.invoke({'cuisine': 'indian'})  # ì²«ë²ˆì§¸ chain ì¸ chef_chain ì˜ {cuisine} ì— ì „ë‹¬\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe11e8-dbe1-40f6-b962-f8d19624f0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7baf7dc5-36e7-4555-b2df-7640cfba8598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a vegetarian version of Chicken Tikka Masala, you can easily substitute the chicken with a plant-based alternative like tofu or paneer. Here's how you can adapt the recipe:\n",
      "\n",
      "**Ingredients:**\n",
      "- 1 lb firm tofu or paneer, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt (use plant-based yogurt for a vegan option)\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 tablespoons vegetable oil\n",
      "- 2 tablespoons garam masala\n",
      "- 1 tablespoon ground cumin\n",
      "- 1 tablespoon paprika\n",
      "- 1 tablespoon minced garlic\n",
      "- 1 tablespoon minced ginger\n",
      "- 1 teaspoon turmeric\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- Salt and pepper to taste\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 cup coconut cream (or any plant-based heavy cream)\n",
      "- Fresh cilantro for garnish\n",
      "- Cooked rice or naan bread for serving\n",
      "\n",
      "**Instructions:**\n",
      "1. Follow the same marinating process as the original recipe, but use tofu or paneer instead of chicken. Marinate for at least 1 hour or overnight for best results.\n",
      "   \n",
      "2. Instead of baking the chicken, you can pan-fry or bake the marinated tofu or paneer until they are cooked through and slightly crispy.\n",
      "   \n",
      "3. In a large skillet, proceed with the sauce as directed in the original recipe, using tomato sauce and coconut cream (or any plant-based heavy cream) instead of dairy cream.\n",
      "   \n",
      "4. Add the cooked tofu or paneer to the sauce and simmer for 10 minutes to allow the flavors to blend.\n",
      "   \n",
      "5. Serve the Vegetarian Tikka Masala over rice or with naan bread, garnished with fresh cilantro.\n",
      "\n",
      "By making these simple swaps, you can enjoy a delicious vegetarian version of Chicken Tikka Masala that's just as flavorful and satisfying!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951fcba-9508-4ac0-9262-c988913d4bed",
   "metadata": {},
   "source": [
    "## streaming= ê³¼ callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ad979-8515-42c0-be83-e0bf058fd1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â†‘ ì „ë¶€ ì‹¤í–‰ ì™„ë£Œ ë ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ëŠ”ê²Œ ì§€ë£¨í•˜ë‹¤.\n",
    "#   ì–´ë–»ê²Œ ì§„í–‰ë˜ëŠ”ì§€ë„ ê¶ê¸ˆí•˜ë‹¤.\n",
    "#   ì§„í–‰ë˜ëŠ” ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ í• ìˆ˜ ìˆë‹¤!\n",
    "\n",
    "# Chat model ì˜ streaming=\n",
    "#  streaming ì€ LLM model ì˜ ì‘ë‹µ(resposne) ì´ ìƒì„±ë˜ëŠ” ê²ƒì„\n",
    "#    ì‹¤ì‹œê°„ìœ¼ë¡œ(?) ë³´ê²Œ í•´ì¤Œ.\n",
    "\n",
    "# callbacks=[StreamingStdOutCallbackHandler()]\n",
    "#    ë³¼ìˆ˜ ìˆëŠ” ë¬¸ì(í† í°)ê°€ ìƒê¸¸ ë•Œë§ˆë‹¤ print í•´ì¤€ë‹¤.\n",
    "\n",
    "# callbacks ëŠ” ë‹¤ì–‘í•œ 'event' ê°ì§€ë„ ê°€ëŠ¥\n",
    "#    LLM ì´ ì‘ì—…ì„ ì‹œì‘í–ˆë‹¤ê±°ë‚˜, ëëƒˆë‹¤ê±°ë‚˜.\n",
    "#    ë¬¸ìë¥¼ ìƒì„±í–ˆë‹¤ê±°ë‚˜, ì—ëŸ¬ê°€ ë°œìƒí•˜ê±°ë‚˜..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99619641-1364-4cc9-874f-2767489e38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "332300e7-3ffa-45d0-be1e-5b19c36b8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85bb6911-fef5-4917-b0bb-ebdb323997a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is full of delicious flavors and spices. Let's make a classic dish - Butter Chicken (Murgh Makhani). Here's a simple recipe for you to try at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken thighs or breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 1 teaspoon ground turmeric\n",
      "- 1 teaspoon ground cumin\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 1 can (14 oz) tomato puree\n",
      "- 1 cup heavy cream\n",
      "- 2 tablespoons butter\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro leaves for garnish\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, marinate the chicken pieces with yogurt, turmeric, cumin, coriander, chili powder, salt, and pepper. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. In a large skillet or pan, heat the vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes.\n",
      "\n",
      "3. Add the minced garlic and grated ginger to the pan and cook for another 2 minutes until fragrant.\n",
      "\n",
      "4. Add the marinated chicken pieces to the pan and cook until browned on all sides, about 5-7 minutes.\n",
      "\n",
      "5. Stir in the tomato puree and simmer for 10-15 minutes, stirring occasionally.\n",
      "\n",
      "6. Add the heavy cream and butter to the pan, stirring until the butter is melted and the sauce is well combined.\n",
      "\n",
      "7. Taste and adjust seasoning with salt and pepper as needed.\n",
      "\n",
      "8. Serve the butter chicken hot over steamed rice or with naan bread. Garnish with fresh cilantro leaves.\n",
      "\n",
      "Enjoy your homemade Butter Chicken! Feel free to adjust the spice levels to suit your taste preferences.For a vegetarian version of Butter Chicken (Murgh Makhani), we can replace the chicken with a suitable alternative like paneer or tofu. Here's how you can adapt the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb paneer or extra-firm tofu, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt (you can use plant-based yogurt for a vegan option)\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 1 teaspoon ground turmeric\n",
      "- 1 teaspoon ground cumin\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 1 can (14 oz) tomato puree\n",
      "- 1 cup heavy cream (substitute with coconut cream for a vegan version)\n",
      "- 2 tablespoons butter (use vegan butter if desired)\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro leaves for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Marinate the paneer or tofu with yogurt, turmeric, cumin, coriander, chili powder, salt, and pepper. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Follow the same steps for cooking the onion, garlic, and ginger in vegetable oil until softened.\n",
      "\n",
      "3. Add the marinated paneer or tofu to the pan and cook until lightly browned on all sides.\n",
      "\n",
      "4. Proceed with adding the tomato puree and simmering for 10-15 minutes.\n",
      "\n",
      "5. Add the heavy cream (or coconut cream) and butter (or vegan butter) to the pan, stirring until well combined.\n",
      "\n",
      "6. Adjust the seasoning with salt and pepper as needed.\n",
      "\n",
      "7. Serve the vegetarian Butter \"Chicken\" hot over steamed rice or with naan bread. Garnish with fresh cilantro leaves.\n",
      "\n",
      "Enjoy your vegetarian version of Butter Chicken! The paneer or tofu will absorb the flavors beautifully, giving you a delicious and satisfying meal.âœ… For a vegetarian version of Butter Chicken (Murgh Makhani), we can replace the chicken with a suitable alternative like paneer or tofu. Here's how you can adapt the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb paneer or extra-firm tofu, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt (you can use plant-based yogurt for a vegan option)\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 1 teaspoon ground turmeric\n",
      "- 1 teaspoon ground cumin\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 1 can (14 oz) tomato puree\n",
      "- 1 cup heavy cream (substitute with coconut cream for a vegan version)\n",
      "- 2 tablespoons butter (use vegan butter if desired)\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro leaves for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Marinate the paneer or tofu with yogurt, turmeric, cumin, coriander, chili powder, salt, and pepper. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Follow the same steps for cooking the onion, garlic, and ginger in vegetable oil until softened.\n",
      "\n",
      "3. Add the marinated paneer or tofu to the pan and cook until lightly browned on all sides.\n",
      "\n",
      "4. Proceed with adding the tomato puree and simmering for 10-15 minutes.\n",
      "\n",
      "5. Add the heavy cream (or coconut cream) and butter (or vegan butter) to the pan, stirring until well combined.\n",
      "\n",
      "6. Adjust the seasoning with salt and pepper as needed.\n",
      "\n",
      "7. Serve the vegetarian Butter \"Chicken\" hot over steamed rice or with naan bread. Garnish with fresh cilantro leaves.\n",
      "\n",
      "Enjoy your vegetarian version of Butter Chicken! The paneer or tofu will absorb the flavors beautifully, giving you a delicious and satisfying meal.\n"
     ]
    }
   ],
   "source": [
    "# ìœ„ ChatModel ë¡œ ë‹¤ì‹œ chain ìƒì„±\n",
    "chef_chain = chef_prompt | chat\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "final_chain = {'recipe': chef_chain} | veg_chain\n",
    "\n",
    "result = final_chain.invoke({\n",
    "    \"cuisine\": \"indian\",\n",
    "})\n",
    "\n",
    "print('âœ…', result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf4189-dcf9-4464-8fdc-faa68f6c4b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be188172-8f91-46d7-9fe0-56003ee6e6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f7e73-9205-4939-9af4-a792d7a8e8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb6e35-eace-48e6-8d31-9c44acee1140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab490f-f078-43e2-a10b-260b781741ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2da776-c17d-424e-bc77-06c06c7c0ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d67e9-d39d-4121-a6b7-8e03c73116e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf23f55-07f7-48a9-a2b8-380cb8745c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255fc5e-244f-46b3-95d1-c8e10eede418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b0fe5-1897-49ba-bcbf-48ff209c0dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2edbca5-deaf-4bb9-a8e1-1d606b2f90e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c92961-85f4-459c-bdb1-8b1d0f8a3656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bbb54-565b-4bb9-88f1-1139ae265ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46460972-7343-4e4e-8e0e-6b9bc0c85386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df020a84-2522-4630-9017-2a7ebed070cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f5af6-c395-4aef-bf30-09e7c6700b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ec4d9-74fe-4684-aa10-022e2982a205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b12c7-f3b8-4a17-bafd-d63c70ea62eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41daef94-b7cf-4a29-926f-a5ce249a14d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4284983-75d5-48c0-a597-9f8d8cfcfecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4e3a9-cfcb-4ba6-a7e6-e98372bbd3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308b1a3-f37e-4a81-807e-9d04a44ca404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05923eac-978f-47ea-84f5-39d1d6b1341a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8802c8-b23d-4dff-8f86-d3e3c431da59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f1e16-ee9c-440b-b366-29c4eb7b9feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a676c-3e67-4f60-8999-e710c0496a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889d864-22f9-46fd-a20c-92f4aa8472c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dca34-7236-4757-b855-89ae3115d7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc81785-3a3a-452e-a39d-415b7cbb9243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5062c-e086-4493-ab4a-6b33e2c225fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5a621-094a-4901-be73-e5a18c2c1cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe19ace-2847-42f5-9878-cf1938501d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102578c-506f-4fb2-b224-c545f058164f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ccd82-c752-40db-95a0-2c9afeacf4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d4e10-00d1-4d01-8778-007f15c76dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88c5fe-28ee-45f2-b067-fc867881f022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb83eb-ff0e-4b6d-b0df-5a7818f79724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80cb126-2b72-4f12-a197-325e7196facd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bcadb-32d0-4daa-9b47-22c68d0e7663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e498084-becd-45d6-8090-68675841ee76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc446a2f-4412-4b2f-a7aa-a2a3e0ef77b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93374220-d222-492d-af5e-a05487a01b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb5c90-3a10-4661-aeb5-553dd9fb0236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde6bc8-302e-4986-9841-daa7a5114160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150da64-641e-4215-bbaf-f3aaddb98b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
